# -*- coding: utf-8 -*-
"""
iBasketball JSON Scraper
========================
×’×–×™×¨×” ×-ibasketball.co.il - ×©××™×¨×” ×‘-JSON ×¢× ×§×•×‘×¥ × ×¤×¨×“ ×œ×›×œ ××•×‘×™×™×§×˜
"""

import requests
import json
import time
import os
from pathlib import Path
from datetime import datetime

from utils import log_message, get_soup
from models import generate_player_id, generate_game_id, normalize_season
from .base_scraper import BaseScraper
from .processors import DataNormalizer, StatsCalculator


class IBasketballScraper(BaseScraper):
    """×’×–×™×¨×” ×-ibasketball.co.il ×¢× ×©××™×¨×” ×‘-JSON"""
    
    def _init_processors(self):
        """××ª×—×•×œ processors"""
        self.normalizer = DataNormalizer(self.league_id, self.league_code)
        self.stats_calc = StatsCalculator()
        
        # ×˜×¢×™× ×ª ××™×¤×•×™ ×§×‘×•×¦×•×ª
        if not self.normalizer.load_team_mapping():
            raise ValueError("Failed to load team mapping")
        
        # ×™×¦×™×¨×ª ××‘× ×” ×ª×™×§×™×•×ª JSON
        self._create_json_structure()
    
    def _create_json_structure(self):
        """×™×¦×™×¨×ª ××‘× ×” ×ª×™×§×™×•×ª ×œ××‘× ×” JSON"""
        base = Path('data')
        
        # âœ… ××‘× ×”: data/players/{league}/
        self.players_folder = base / 'players' / self.league_code
        # âœ… ××‘× ×”: data/games/{league}/{season}/
        self.games_folder = base / 'games' / self.league_code / self.league_config['season']
        
        self.players_folder.mkdir(parents=True, exist_ok=True)
        self.games_folder.mkdir(parents=True, exist_ok=True)
        
        self.log(f"âœ… JSON structure ready")
        self.log(f"   Players: {self.players_folder}")
        self.log(f"   Games: {self.games_folder}")
    
    # ============================================
    # PLAYER FILE MANAGEMENT
    # ============================================
    
    def _save_player_details(self, player_id, folder_name, details):
        """×©××•×¨ ×¤×¨×˜×™ ×©×—×§×Ÿ ×œ×§×•×‘×¥ JSON"""
        player_folder = self.players_folder / folder_name
        player_folder.mkdir(exist_ok=True)
        
        details['last_updated'] = datetime.now().isoformat()
        
        file_path = player_folder / f'{player_id}_details.json'
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(details, f, ensure_ascii=False, indent=2)

    def _save_player_history(self, player_id, folder_name, history_raw):
        """×©××•×¨ ×”×™×¡×˜×•×¨×™×” ×©×œ ×©×—×§×Ÿ - ×¤×•×¨××˜ ×©×˜×•×— ×œ×˜×‘×œ×”"""
        player_folder = self.players_folder / folder_name
        player_folder.mkdir(exist_ok=True)
        
        
        # âœ… ×‘×“×™×§×ª ×ª×§×™× ×•×ª
        if not isinstance(history_raw, dict):
            self.log(f"   âš ï¸  Invalid history data type")
            file_path = player_folder / f'{player_id}_history.json'
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump([], f, ensure_ascii=False, indent=2)
            return
        
        # âœ… ×”××¨×” ×œ×¤×•×¨××˜ ×©×˜×•×— + ×¡×™× ×•×Ÿ ×§×˜ ×¡×œ
        history_rows = []
        for season, entries in history_raw.items():
            if not isinstance(entries, list):
                continue
            
            for entry in entries:
                if not isinstance(entry, dict):
                    continue
                
                league_name = entry.get('league', '')
                
                # âœ… ×“×œ×’ ×¢×œ ×§×˜ ×¡×œ
                if any(x in league_name for x in ['×§×˜ ×¡×œ', '×§×˜-×¡×œ',  '×™×œ×“×•×ª','×™×œ×“×™×', '×§×˜×¡×œ']):
                    continue
                
                history_rows.append({
                    'player_id': player_id,
                    'season': season,
                    'team_name': entry.get('team', ''),
                    'league_name': self._clean_league_name(league_name),
                    'league_id': self.league_id
                })
        
        file_path = player_folder / f'{player_id}_history.json'
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(history_rows, f, ensure_ascii=False, indent=2)


    def _load_player_details(self, folder_name):
        """×˜×¢×Ÿ ×¤×¨×˜×™ ×©×—×§×Ÿ ××§×•×‘×¥"""
        player_folder = self.players_folder / folder_name
        
        # ××¦× ××ª ×”×§×•×‘×¥ ×©××ª×—×™×œ ×‘-player_id
        details_files = list(player_folder.glob('*_details.json'))
        
        if not details_files:
            return None
        
        with open(details_files[0], 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _load_player_history(self, folder_name):
        """×˜×¢×Ÿ ×”×™×¡×˜×•×¨×™×” ×©×œ ×©×—×§×Ÿ"""
        player_folder = self.players_folder / folder_name
        
        # ××¦× ××ª ×”×§×•×‘×¥ ×©××ª×—×™×œ ×‘-player_id
        history_files = list(player_folder.glob('*_history.json'))
        
        if not history_files:
            return None
        
        with open(history_files[0], 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _player_exists(self, folder_name):
        """×‘×“×•×§ ×× ×©×—×§×Ÿ ×§×™×™×"""
        player_folder = self.players_folder / folder_name
        return player_folder.exists() and any(player_folder.glob('*_details.json'))
    
    def _needs_player_update(self, folder_name):
        """×‘×“×•×§ ×× ×©×—×§×Ÿ ×¦×¨×™×š ×¢×“×›×•×Ÿ"""
        player_folder = self.players_folder / folder_name
        
        # ×‘×“×•×§ ×× ×”×ª×™×§×™×™×” ×§×™×™××ª
        if not player_folder.exists():
            return True, "New player"
        
        # ×—×¤×© ×§×‘×¦×™×
        details_files = list(player_folder.glob('*_details.json'))
        history_files = list(player_folder.glob('*_history.json'))
        
        # âœ… ×× ×™×© ×’× details ×•×’× history - ×”×©×—×§×Ÿ ×§×™×™× ×•××œ×
        if details_files and history_files:
            # ×‘××¦×‘ QUICK - ×“×œ×’
            if self.scrape_mode == 'quick':
                return False, "Complete (quick mode)"
            
      # ×‘××¦×‘ FULL - ×‘×“×•×§ ×× ×™×© × ×ª×•× ×™× ×—×¡×¨×™×
        try:
            with open(details_files[0], 'r', encoding='utf-8') as f:
                details = json.load(f)
            
            # ×‘×“×•×§ ×©×“×•×ª ×—×•×‘×”
            if not details.get('date_of_birth') or details['date_of_birth'] == '':
                return True, "Missing DOB"
            if not details.get('height') or details['height'] == '':
                return True, "Missing height"
            if not details.get('jersey_number') or details['jersey_number'] == '':
                return True, "Missing number"
            
            return False, "Complete data"
        except:
            return True, "Corrupted file"
    
        # ×× ×—×¡×¨ ××—×“ ××”×§×‘×¦×™×
        if not details_files:
            return True, "Missing details"
        if not history_files:
            return True, "Missing history"
        
        return True, "Unknown"
        # ============================================
    # GAME FILE MANAGEMENT
    # ============================================
    
    def _save_game(self, game_data):
        """×©××•×¨ ××©×—×§ ×œ×§×•×‘×¥ JSON"""
        game_id = game_data['game_id']
        game_data['scraped_at'] = datetime.now().isoformat()
        
        file_path = self.games_folder / f"{game_id}.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(game_data, f, ensure_ascii=False, indent=2)
    
    def _load_game(self, game_id):
        """×˜×¢×Ÿ ××©×—×§ ××§×•×‘×¥"""
        file_path = self.games_folder / f"{game_id}.json"
        
        if not file_path.exists():
            return None
        
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _game_exists(self, game_id):
        """×‘×“×•×§ ×× ××©×—×§ ×§×™×™×"""
        return (self.games_folder / f"{game_id}.json").exists()
    
    # ============================================
    # PLAYER SCRAPING
    # ============================================
    
    def _update_player_details(self):
        """×¢×“×›×•×Ÿ ×¤×¨×˜×™ ×©×—×§× ×™×"""
        from models import generate_player_folder_name  # âœ… import
        
        self.log("STEP 1: UPDATING PLAYER DETAILS")
        
        players = self._scrape_player_list()
        if not players:
            self.log("âŒ No players found")
            return False
        
        self.log(f"Found {len(players)} players")
        
        new_players = 0
        updated_players = 0
        skipped_players = 0
        
        for i, player in enumerate(players, 1):
            player_name = player['Name']
            current_team_raw = player['Team']
            player_url = player['URL']
            
            # × ×¨××•×œ ×©× ×§×‘×•×¦×”
            team_info = self.normalizer.normalize_team_name(current_team_raw)
            current_team = team_info['club_name']
            team_id = team_info['team_id']
            
            # âœ… ×™×¦×™×¨×ª folder_name ××”×™×¨ (×œ×œ× ×ª××¨×™×š ×œ×™×“×”)
            folder_name = generate_player_folder_name(player_name, current_team)
            
            self.log(f"[{i}/{len(players)}] Checking: {player_name}")
            self.log(f"   ğŸ“ Folder: {folder_name}")
            
            # ×‘×“×•×§ ×× ×¦×¨×™×š ×œ×’×–×•×¨
            needs_update, reason = self._needs_player_update(folder_name)
            
            if needs_update:
                self.log(f"   âš™ï¸ Updating: {reason}")
                
                try:
                    # âœ… ×¢×›×©×™×• ×’×–×•×¨ ×¤×¨×˜×™× (×›×•×œ×œ ×ª××¨×™×š ×œ×™×“×”)
                    details_raw = self._scrape_player_details(player_url)
                    
                    # âœ… ×¦×•×¨ player_id ×¢× ×ª××¨×™×š ×œ×™×“×”
                    player_id = generate_player_id(player_name, details_raw['Date Of Birth'], self.league_id)
                    
                    self.log(f"   ğŸ†” Player ID: {player_id}")
                    
                    # ×’×–×•×¨ ×”×™×¡×˜×•×¨×™×”
                    history_raw = self._scrape_player_history(player_url)

                    # âœ… ×©××™×¨×” ×™×©×™×¨×•×ª - ×”×¤×•× ×§×¦×™×” ×ª×˜×¤×œ ×‘×”××¨×”
                    self._save_player_history(player_id, folder_name, history_raw)

                                        
                    # ×”×›× ×ª ×¤×¨×˜×™×
                    details = {
                        'player_id': player_id,
                        'name': player_name,
                        'current_team_id': team_id,
                        'league_id': self.league_id,
                        'date_of_birth': details_raw['Date Of Birth'],
                        'height': details_raw['Height'],
                        'jersey_number': details_raw['Number']
                    }

                    self._save_player_details(player_id, folder_name, details)
                   
                    
                    if not (self.players_folder / folder_name).exists():
                        new_players += 1
                    else:
                        updated_players += 1
                    
                    self.log(f"   âœ… Saved")
                    
                except Exception as e:
                    self.log(f"   âŒ Error: {e}")
            else:
                skipped_players += 1
                self.log(f"   â­ï¸  Skipped: {reason}")
            
            time.sleep(1)
        
        self.log(f"âœ… Total: {len(players)} | New: {new_players} | Updated: {updated_players} | Skipped: {skipped_players}")
        
        return True
        
    def _scrape_player_list(self):
        """×’×–×™×¨×ª ×¨×©×™××ª ×©×—×§× ×™× ××“×£ ×”×œ×™×’×”"""
        soup = get_soup(self.league_config['url'])
        if not soup:
            return []
        
        players = []
        for player_tag in soup.select(".player-gallery a.player"):
            name = player_tag.get_text("|", strip=True).split('|')[0]
            team = player_tag.find("span").get_text(strip=True)
            player_url = player_tag["href"]
            players.append({"Name": name, "Team": team, "URL": player_url})
        
        return players
    
    def _scrape_player_details(self, player_url):
        """×’×–×™×¨×ª ×¤×¨×˜×™ ×©×—×§×Ÿ ×‘×•×“×“"""
        soup = get_soup(player_url)
        if not soup:
            return {"Date Of Birth": "", "Height": "", "Number": ""}
        
        # ×ª××¨×™×š ×œ×™×“×”
        dob = soup.find("div", class_="data-birthdate")
        dob_text = dob.get_text("|", strip=True).split("|")[-1] if dob else ""
        dob_formatted = "/".join(dob_text.split("-")[::-1]) if dob_text else ""
        
        # ×’×•×‘×”
        height = soup.find("div", class_="data-other", attrs={"data-metric": "×’×•×‘×”"})
        height_text = height.get_text("|", strip=True).split("|")[-1] if height else ""
        
        # ××¡×¤×¨ ×©×—×§×Ÿ
        number = ""
        general_ul = soup.find("ul", class_="general")
        if general_ul:
            for li in general_ul.find_all("li"):
                label = li.find("span", class_="label")
                if label and "××¡×¤×¨" in label.text:
                    data_span = li.find("span", class_="data-number")
                    if data_span:
                        number = data_span.get_text(strip=True)
                        break
        
        return {
            "Date Of Birth": dob_formatted,
            "Height": height_text,
            "Number": number
        }
    
    def _scrape_player_history(self, player_url):
        """×’×–×™×¨×ª ×”×™×¡×˜×•×¨×™×™×ª ×§×‘×•×¦×•×ª"""
        soup = get_soup(player_url)
        if not soup:
            return {}
        
        history_tag = soup.find("div", class_="data-teams")
        history = {}
        youth_count = 0
        
        # âœ… ××¢×§×‘ ××—×¨×™ ×¦×™×¨×•×¤×™× ×©×›×‘×¨ × ×•×¡×¤×•
        seen_combinations = set()
        
        if history_tag:
            br_tags = history_tag.find_all('br')
            
            for br in br_tags:
                season_span = br.find_next_sibling('span', title=True)
                
                if season_span:
                    season_raw = season_span.get_text(strip=True)
                    season = normalize_season(season_raw)
                    
                    team_link = season_span.find_next_sibling('a')
                    if team_link:
                        team = team_link.get_text(strip=True)
                        league_link = team_link.find_next_sibling('a')
                        
                        if league_link:
                            league = league_link.get_text(strip=True)
                            
                            # âœ… ×‘×“×•×§ ×× ×”×¦×™×¨×•×£ ×›×‘×¨ ×§×™×™×
                            combination = (season, team)
                            
                            if combination in seen_combinations:
                                continue  # âœ… ×“×œ×’ ×¨×§ ×¢×œ ×”×©×•×¨×” ×”×–××ª, ×”××©×š ×œ×œ×•×œ××” ×”×‘××”
                            
                            # âœ… ×¡××Ÿ ×©×¨××™× ×• ××ª ×”×¦×™×¨×•×£ ×”×–×”
                            seen_combinations.add(combination)
                            
                            # ×¢×¦×•×¨ ××—×¨×™ 2 ×œ×™×’×•×ª × ×•×¢×¨
                            if "× ×•×¢×¨" in league:
                                youth_count += 1
                                if youth_count > 1:
                                    break  # âœ… ×¨×§ ×¤×” ×¢×•×¦×¨×™× ××ª ×”×›×œ
                            
                            # ×©××•×¨ ×‘×¤×•×¨××˜
                            if season not in history:
                                history[season] = []
                            
                            history[season].append({
                                'team': team,
                                'league': league
                            })
        
        return history

    def _clean_league_name(self, league_name):
        """× ×™×§×•×™ ×©× ×œ×™×’×” ×××™×œ×™× ××™×•×ª×¨×•×ª"""
        words_to_remove = ['× ×©×™×', '×’', '×’××¨×¡×œ', '×¢×œ×™×•×Ÿ', '×¦×¤×•×Ÿ', '×“×¨×•×']
        
        cleaned = league_name
        for word in words_to_remove:
            cleaned = cleaned.replace(f' {word}', '')
            cleaned = cleaned.replace(f'{word} ', '')
            if cleaned == word:
                cleaned = ''
        
        cleaned = ' '.join(cleaned.split())
        return cleaned.strip()



    # ============================================
    # GAME SCRAPING
    # ============================================
    
    def _update_game_details(self):
        """×¢×“×›×•×Ÿ ××©×—×§×™×"""
        self.log("STEP 1: UPDATING GAME DETAILS")
        
        # ×”×•×¨×“×ª ×œ×•×— ××©×—×§×™×
        games_df = self._download_games_schedule()
        if games_df is None:
            self.log("âŒ Failed to download games schedule")
            return False
        
        # × ×¨××•×œ ×©××•×ª ×§×‘×•×¦×•×ª
        games_df = self._normalize_schedule_teams(games_df)
        
        self.log(f"Found {len(games_df)} games in schedule")
        
        # âœ… ×©××™×¨×ª ×œ×•"×– ××œ× ×›-JSON
        self._save_full_schedule(games_df)
        
        # ×’×–×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×¨×§ ×œ××©×—×§×™× ×¢× ×ª×•×¦××”
        return self._scrape_all_games(games_df)
    
    def _save_full_schedule(self, games_df):
        """×©××•×¨ ×œ×•"×– ××œ× ×©×œ ×”×œ×™×’×”"""
        import pandas as pd
        
        schedule_data = []
        
        for idx, row in games_df.iterrows():
            game_code = str(row.get('Code', ''))
            
            schedule_data.append({
                'game_id': f"{self.league_id}_{game_code}",
                'league_id': self.league_id,
                'season': self.league_config['season'],
                'code': game_code,
                'date': row.get('×ª××¨×™×š', ''),
                'time': row.get('Time', ''),
                'round': row.get('××—×–×•×¨', ''),
                'home_team': row.get('Home Team', ''),
                'away_team': row.get('Away Team', ''),
                'home_score': int(row['Home Score']) if pd.notna(row.get('Home Score')) else None,
                'away_score': int(row['Away Score']) if pd.notna(row.get('Away Score')) else None,
                'venue': row.get('Venue', ''),
                'status': 'completed' if pd.notna(row.get('Home Score')) else 'scheduled'
            })
        
        schedule_path = self.games_folder / 'schedule.json'
        with open(schedule_path, 'w', encoding='utf-8') as f:
            json.dump(schedule_data, f, ensure_ascii=False, indent=2)
        
        self.log(f"âœ… Full schedule saved: {len(schedule_data)} games")
    
    def _scrape_all_games(self, games_df):
        """×’×–×™×¨×ª ××©×—×§×™× - ×¨×§ ×¢× ×ª×•×¦××”"""
        import pandas as pd
        
        games_scraped = 0
        games_skipped = 0
        
        for idx, row in games_df.iterrows():
            # âœ… ×“×œ×’ ×× ××™×Ÿ ×ª×•×¦××”
            if pd.isna(row.get('Home Score')) or pd.isna(row.get('Away Score')):
                continue
            
            # âœ… ×‘×“×•×§ ×× ×™×© Code
            if pd.isna(row.get('Code')) or row['Code'] == '':
                continue
            
            game_code = str(row['Code'])
            game_url = f"https://ibasketball.co.il/event/{game_code}/"
            game_id = f"{self.league_id}_{game_code}"
            
            # ×‘×“×•×§ ×× ×”××©×—×§ ×§×™×™×
            if self._game_exists(game_id):
                games_skipped += 1
                continue
            
            self.log(f"   [{idx+1}/{len(games_df)}] Scraping game: {game_id}")
            
            # ×’×–×•×¨ ××ª ×”××©×—×§
            game_data = self._scrape_single_game(game_id, game_url, row)
            
            if game_data:
                self._save_game(game_data)
                games_scraped += 1
            
            time.sleep(1)
        
        self.log(f"âœ… Games updated: {games_scraped} scraped, {games_skipped} skipped")
        return True
    
    
    def _download_games_schedule(self):
        """×”×•×¨×“×ª ×œ×•×— ××©×—×§×™× ××”××ª×¨"""
        league_url = self.league_config['url']
        soup = get_soup(league_url)
        if not soup:
            return None
        
        export_link = soup.find('a', href=lambda x: x and ('export' in x or 'feed=xlsx' in x))
        if not export_link:
            self.log("âŒ Export link not found")
            import pandas as pd
            return pd.DataFrame()
        
        export_url = export_link['href']
        
        if not export_url.startswith('http'):
            if export_url.startswith('?'):
                export_url = f"{league_url}{export_url}"
            else:
                export_url = f"https://ibasketball.co.il{export_url}"
        
        self.log(f"   Downloading from: {export_url}")
        
        try:
            import pandas as pd
            import os
            from pathlib import Path
            
            response = requests.get(export_url, timeout=30)
            response.raise_for_status()
            
            # âœ… ×©××•×¨ ×§×•×‘×¥ ×–×× ×™
            temp_excel = self.games_folder / 'temp_games.xlsx'
            with open(temp_excel, 'wb') as f:
                f.write(response.content)
            
            # âœ… ×§×¨× ××”×§×•×‘×¥
            df = pd.read_excel(temp_excel, engine='openpyxl')
            os.remove(temp_excel)
            
            self.log(f"   âœ… Downloaded {len(df)} games")
            return df
            
        except Exception as e:
            self.log(f"âŒ Error downloading schedule: {e}")
            return None


    def _normalize_schedule_teams(self, games_df):
        """× ×¨××•×œ ×©××•×ª ×§×‘×•×¦×•×ª ×‘×œ×•×— ××©×—×§×™×"""
        import pandas as pd
        
        # ×©×™× ×•×™ ×©××•×ª ×¢××•×“×•×ª ×œ×× ×’×œ×™×ª
        column_renames = {
            '×œ×™×’×”': 'League',
            '××•×¢×“': 'Round',
            '×ª××¨×™×š': 'Date',
            '×©×¢×”': 'Time',
            '×‘×™×ª': 'Home Team',
            '××•×¨×—': 'Away Team',
            '×ª. ×‘×™×ª': 'Home Score',
            '×ª. ××•×¨×—': 'Away Score',
            '×”×™×›×œ': 'Arena',
            '×§×™×©×•×¨': 'Link'
        }
        
        games_df = games_df.rename(columns=column_renames)
        
        # × ×¨××•×œ ×‘×™×ª
        if 'Home Team' in games_df.columns:
            games_df['Home Team'] = games_df['Home Team'].apply(
                lambda x: self.normalizer.normalize_team_name(x)['club_name'] if pd.notna(x) else x
            )
        
        # × ×¨××•×œ ××•×¨×—
        if 'Away Team' in games_df.columns:
            games_df['Away Team'] = games_df['Away Team'].apply(
                lambda x: self.normalizer.normalize_team_name(x)['club_name'] if pd.notna(x) else x
            )
        
        return games_df
    
    
        
    def _scrape_single_game(self, game_id, game_url, schedule_row):
        """×’×–×™×¨×ª ××©×—×§ ×‘×•×“×“"""
        import pandas as pd
        
        soup = get_soup(game_url)
        if not soup:
            return None
        
        # ×¤×¨×˜×™ ××©×—×§ ×‘×¡×™×¡×™×™×
        home_team = schedule_row.get('Home Team', '')
        away_team = schedule_row.get('Away Team', '')
        
        home_team_info = self.normalizer.normalize_team_name(home_team)
        away_team_info = self.normalizer.normalize_team_name(away_team)
        
        game_data = {
            'game_id': game_id,
            'league_id': self.league_id,
            'season': self.league_config['season'],
            'date': schedule_row.get('Date', ''),
            'time': schedule_row.get('Time', ''),
            'round': schedule_row.get('Round', ''),
            'home_team': home_team_info['club_name'],
            'home_team_id': home_team_info['team_id'],
            'away_team': away_team_info['club_name'],
            'away_team_id': away_team_info['team_id'],
            'home_score': int(schedule_row['Home Score']) if pd.notna(schedule_row.get('Home Score')) else None,
            'away_score': int(schedule_row['Away Score']) if pd.notna(schedule_row.get('Away Score')) else None,
            'arena': schedule_row.get('Arena', ''),
            'status': 'completed' if pd.notna(schedule_row.get('Home Score')) else 'scheduled'
        }
        
        # ×’×–×™×¨×ª ×¨×‘×¢×™×
        quarters = self._scrape_quarters(soup, game_id)
        if quarters:
            game_data['quarters'] = quarters
        
        # ×’×–×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×—×§× ×™×
        player_stats = self._scrape_player_stats(soup, game_id)
        if player_stats:
            game_data['player_stats'] = player_stats
        
        # ×’×–×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×§×‘×•×¦×ª×™×•×ª
        team_stats = self._scrape_team_stats(soup, game_id)
        if team_stats:
            game_data['team_stats'] = team_stats
        
        return game_data
    
    def _scrape_quarters(self, soup, game_id):
        """×’×–×™×¨×ª × ×™×§×•×“ ×œ×¤×™ ×¨×‘×¢×™×"""
        quarters = []
        
        quarters_section = soup.find('div', class_='sp-template-event-blocks')
        if not quarters_section:
            return quarters
        
        table = quarters_section.find('table')
        if not table:
            return quarters
        
        tbody = table.find('tbody')
        if not tbody:
            return quarters
        
        rows = tbody.find_all('tr')
        for row in rows[:-1]:  # ×œ× ×›×•×œ×œ ×©×•×¨×ª ×¡×™×›×•×
            cells = row.find_all('td')
            if len(cells) >= 5:
                try:
                    quarter_num = len(quarters) + 1
                    home_score = int(cells[-2].get_text(strip=True))
                    away_score = int(cells[-1].get_text(strip=True))
                    
                    quarters.append({
                        'quarter': quarter_num,
                        'home_score': home_score,
                        'away_score': away_score
                    })
                except:
                    continue
        
        return quarters
    
    def _scrape_player_stats(self, soup, game_id):
        """×’×–×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×—×§× ×™×"""
        player_stats = []
        
        # ××¦×™××ª ×›×œ ×”×˜×‘×œ××•×ª ×©×œ ×©×—×§× ×™×
        performance_sections = soup.find_all('div', class_='sp-template-event-performance')
        
        for section in performance_sections:
            team_header = section.find('h4', class_='sp-table-caption')
            if not team_header:
                continue
            
            team_name_raw = team_header.text.strip()
            team_info = self.normalizer.normalize_team_name(team_name_raw)
            team_id = team_info['team_id']
            
            table = section.find('table', class_='sp-event-performance')
            if not table:
                continue
            
            tbody = table.find('tbody')
            if not tbody:
                continue
            
            for row in tbody.find_all('tr'):
                if 'sp-total-row' in row.get('class', []):
                    continue
                
                cells = row.find_all('td')
                if len(cells) < 2:
                    continue
                
                # ×©× ×©×—×§×Ÿ
                player_cell = cells[0]
                player_link = player_cell.find('a')
                if not player_link:
                    continue
                
                player_name = player_link.get_text(strip=True)
                
                # ×¡×˜×˜×™×¡×˜×™×§×•×ª
                stats = {
                    'game_id': game_id,
                    'player_name': player_name,
                    'team_id': team_id
                }
                
                # ×§×¨×™××ª ×”×¡×˜×˜×™×¡×˜×™×§×•×ª ××”×ª××™×
                for i, cell in enumerate(cells[1:], 1):
                    stat_value = cell.get_text(strip=True)
                    # ×›××Ÿ ×ª×¦×˜×¨×š ×œ×”×•×¡×™×£ ×œ×•×’×™×§×” ×œ×–×™×”×•×™ ××™×–×” stat ×–×”
                    # ×œ×¤×™ ×”××‘× ×” ×©×œ ×”××ª×¨
                
                player_stats.append(stats)
        
        return player_stats
    
    def _scrape_team_stats(self, soup, game_id):
        """×’×–×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×§×‘×•×¦×ª×™×•×ª"""
        team_stats = []
        
        # ×›××Ÿ ×ª×•×¡×™×£ ××ª ×”×œ×•×’×™×§×” ×œ×’×–×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×§×‘×•×¦×ª×™×•×ª
        # ×‘×”×ª×× ×œ××‘× ×” ×©×œ ×”××ª×¨
        
        return team_stats